# ðŸ“Š V26 QUICK REFERENCE GUIDE

## ðŸŽ¯ Cosa Migliora in V26

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MIGLIORAMENTI V26 VISUALIZZATI                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  V25 FEATURES (19)          V26 NUOVE FEATURES (+8)             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•             â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•             â”‚
â”‚  â€¢ ELO Rating               â€¢ Expected Goals (xG)  [+2-3%]       â”‚
â”‚  â€¢ Attack/Defense           â€¢ Rest Days             [+1-2%]       â”‚
â”‚  â€¢ Form                     â€¢ Head-to-Head         [+1-2%]       â”‚
â”‚  â€¢ Efficiency               â€¢ Momentum Decay        [+1%]         â”‚
â”‚  â€¢ Trend                                                          â”‚
â”‚  â€¢ Home Advantage           OPTIMIZZAZIONI                       â”‚
â”‚                             â•â•â•â•â•â•â•â•â•â•â•â•â•â•                       â”‚
â”‚  V25 TRAINING               â€¢ RobustScaler         [+1%]         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•             â€¢ Feature Selection    [+0.5%]       â”‚
â”‚  â€¢ StandardScaler           â€¢ Calibration          [+0.5%]       â”‚
â”‚  â€¢ 85/15 Split              â€¢ GridSearch (Opz.)   [+1-2%]       â”‚
â”‚  â€¢ Stacking                                                       â”‚
â”‚                             TOTALE IMPATTO: +5-7%                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    ACCURACY IMPROVEMENT ROADMAP

     V25: 50.0%  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  V26: 55-60%  âœ…
           â”‚
           â”œâ”€ Features   (+5-6%)  Expected Goals, Rest, H2H, Momentum
           â”œâ”€ Scaling    (+1%)    RobustScaler
           â”œâ”€ Selection  (+0.5%)  SelectKBest
           â””â”€ Calib      (+0.5%)  CalibratedClassifierCV
```

---

## ðŸš€ OPZIONI DI IMPLEMENTAZIONE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TEMPO vs ACCURATEZZA               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  EXPERT              5-6h â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚ +9-12%
â”‚  (GridSearch+All)                   â”‚
â”‚                                     â”‚
â”‚  FULL               3-4h â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     â”‚ +7-9%
â”‚  (All features)                     â”‚
â”‚                                     â”‚
â”‚  QUICK              1-2h â–ˆâ–ˆâ–ˆ        â”‚ +4-5%
â”‚  (xG + Rest only)                   â”‚
â”‚                                     â”‚
â”‚  BASELINE           0.5h â–ˆ          â”‚ 0%
â”‚  (Original V25)                     â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“‹ IMPLEMENTAZIONE CHECKLIST

### FASE 1: SETUP (15 min)
```
[ ] Backup script.py â†’ script_v25_backup.py
[ ] Verifica dipendenze: scikit-learn >= 1.3.0
[ ] Leggi IMPROVEMENT_GUIDE.md
[ ] Scegli OPZIONE A/B/C
```

### FASE 2: CODE (1-3 hours depends on option)
```
QUICK (Option A):
[ ] Copia calculate_xg() dal script_v26_enhancements.py
[ ] Copia calculate_rest_days()
[ ] Modifica build_features_v23_mega() â†’ usa xG + rest
[ ] Test: No NaN, No errors

FULL (Option B):
[ ] Copia tutte 4 nuove funzioni (xG, Rest, H2H, Momentum)
[ ] Copia build_features_v26_enhanced() intera
[ ] Aggiorna train_model():
    [ ] RobustScaler al posto di StandardScaler
    [ ] Aggiungi SelectKBest(k=20)
    [ ] Aggiungi CalibratedClassifierCV
[ ] Test: Accuracy migliore di V25

EXPERT (Option C):
[ ] Fai tutto da FULL
[ ] Aggiungi GridSearchCV per RF hyperparameter tuning
[ ] Aggiungi StratifiedKFold cross-validation
[ ] Monitor CPU/Memory usage
[ ] Test: Aspetta GridSearch completi (5-10 min)
```

### FASE 3: TEST (1-2 hours)
```
[ ] Test 1: Verifica features non NaN
    ```python
    assert not np.isnan(X).any(), "NaN found!"
    ```

[ ] Test 2: Confronta velocitÃ 
    V25: ~4s | V26: ~18s | Aspettato âœ“

[ ] Test 3: Confronta accuracy
    V25: 50.0% | V26: 55%+ | âœ… Migliorato!

[ ] Test 4: Run completo senza errori
    python script.py â†’ Controllare logs
```

### FASE 4: DEPLOY (30 min)
```
[ ] Se V26 accuracy > V25: Mantieni V26
[ ] Se V26 accuracy < V25: Torna a V25
[ ] Update documentation
[ ] Commit changes a git
[ ] Monitor performance live (prima settimana)
```

---

## ðŸŽ¯ FEATURE ENGINEERING EXPLAINED

### 1ï¸âƒ£ Expected Goals (xG)

```python
calculate_xg(team, df_hist, idx, is_home=True)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Expected Goals Formula                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ xG = Avg_Goals_Storico * 0.85           â”‚
â”‚      * (1 + boost_if_recent_good)       â”‚
â”‚                                         â”‚
â”‚ Interpretazione:                        â”‚
â”‚ â€¢ xG > gol_reali â†’ Underperforming      â”‚
â”‚ â€¢ xG < gol_reali â†’ Overperforming       â”‚
â”‚ â€¢ xG ~ gol_reali â†’ Normalizzato         â”‚
â”‚                                         â”‚
â”‚ Range: [0.3, 3.5]                       â”‚
â”‚ Impatto: +2-3% accuracy                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2ï¸âƒ£ Rest Days

```python
calculate_rest_days(team, df_hist, idx)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rest Impact on Performance            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚ â‰¥5 days   â†’  +0.3  (Fresh, energico)â”‚
â”‚ 3-4 days  â†’   0.0  (Normal)         â”‚
â”‚ 1-2 days  â†’  -0.2  (Stanco)         â”‚
â”‚ <1 day    â†’  -0.5  (Molto stanco)   â”‚
â”‚                                      â”‚
â”‚ Effetto: Home team win rate +15%    â”‚
â”‚          con 5+ giorni di riposo    â”‚
â”‚                                      â”‚
â”‚ Range: [-0.5, +0.3]                 â”‚
â”‚ Impatto: +1-2% accuracy             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3ï¸âƒ£ Head-to-Head (H2H)

```python
calculate_h2h(home, away, df_hist)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ H2H Analysis (Ultimi 10 match)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                 â”‚
â”‚ h2h_advantage:                  â”‚
â”‚  = (Home_Win_% - 33%) - baselineâ”‚
â”‚  Range: [-0.4, +0.4]            â”‚
â”‚                                 â”‚
â”‚ Esempio:                        â”‚
â”‚ â€¢ Milan vs Roma: +0.25          â”‚
â”‚   (Milan vince 60% vs Roma)     â”‚
â”‚ â€¢ Roma vs Milan: -0.25          â”‚
â”‚   (Roma vince 10% vs Milan)     â”‚
â”‚                                 â”‚
â”‚ Impatto: +1-2% accuracy         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4ï¸âƒ£ Momentum Decay

```python
calculate_momentum_decay(team, df_hist, idx, decay_rate=0.8)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Recent Form Scoring                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                       â”‚
â”‚ Ultimi match weight:                  â”‚
â”‚ 1st (most recent):  100%              â”‚
â”‚ 2nd:                80%               â”‚
â”‚ 3rd:                64%               â”‚
â”‚ 4th:                51%               â”‚
â”‚ 5th:                41%               â”‚
â”‚ ... decays exponentially              â”‚
â”‚                                       â”‚
â”‚ Points: Win=3, Draw=1, Loss=0         â”‚
â”‚ Momentum = normalized_weighted_points â”‚
â”‚                                       â”‚
â”‚ Range: [-0.5, +0.5]                   â”‚
â”‚ Impatto: +1% accuracy                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ INTEGRAZIONE NEL CODICE

### Step 1: Aggiungi le funzioni

```python
# In script.py, DOPO compute_advanced_stats() e PRIMA di build_features_v23_mega()

def calculate_xg(team, df_hist, idx, is_home=True):
    # Copia dal script_v26_enhancements.py linea ~50

def calculate_rest_days(team, df_hist, idx):
    # Copia dal script_v26_enhancements.py linea ~85

def calculate_h2h(home, away, df_hist):
    # Copia dal script_v26_enhancements.py linea ~130

def calculate_momentum_decay(team, df_hist, idx, is_home=True, decay_rate=0.8):
    # Copia dal script_v26_enhancements.py linea ~165
```

### Step 2: Modifica build_features (QUICK OPTION A)

```python
# PRIMA: usava solo 19 features
X.append([
    row["elo_home"], row["elo_away"],
    h_stats['scored_overall'], ...
    # ... 19 total
])

# DOPO: aggiungi le 8 nuove
X.append([
    # ... 19 original ...
    h_xg, a_xg,                                    # +2 new
    h_rest, a_rest,                                # +2 new
    h2h_adv, h2h_gf, h2h_ga,                      # +3 new
    h_momentum, a_momentum,                        # +2 new
    # = 27 total
])
```

### Step 3: Migliora il training (FULL OPTION B)

```python
# In train_model(), sostituisci:

# PRIMA:
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# DOPO:
from sklearn.preprocessing import RobustScaler
from sklearn.feature_selection import SelectKBest, f_classif

scaler = RobustScaler(quantile_range=(10, 90))
X_scaled = scaler.fit_transform(X)

selector = SelectKBest(f_classif, k=20)
X_selected = selector.fit_transform(X_scaled, y)

# Usa X_selected da qui in poi
X_train = X_selected[:split]
```

### Step 4: Calibra il modello

```python
# DOPO il training dello stacking ensemble:

from sklearn.calibration import CalibratedClassifierCV

cal_clf = CalibratedClassifierCV(clf, method='sigmoid', cv=5)
cal_clf.fit(X_train, y_train)

# Usa cal_clf per predictions
return cal_clf, scaler
```

---

## ðŸ“Š PERFORMANCE TIMELINE

```
Time    â”‚ Activity              â”‚ Cumulative
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0:00    â”‚ Backup & Setup        â”‚ 15 min
0:15    â”‚ Copia functions       â”‚ 45 min
0:45    â”‚ Modify features       â”‚ 1:30 h
1:30    â”‚ Update training       â”‚ 2:00 h
2:00    â”‚ Test 1: No NaN        â”‚ 2:15 h
2:15    â”‚ Test 2: Speed check   â”‚ 2:30 h
2:30    â”‚ Test 3: Accuracy      â”‚ 3:00 h
3:00    â”‚ Bug fixing (if any)   â”‚ 3:30 h
3:30    â”‚ Final validation      â”‚ 4:00 h
4:00    â”‚ âœ… DONE!              â”‚ 4:00 h
```

---

## âš ï¸ COMMON PITFALLS & FIXES

```
Problema                    Soluzione
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NaN in features             Check empty dataframes,
                           return default values

Accuracy worse              Check data leakage,
                           verify feature calculation

Training slow               Expected! V26 = 4.5x slower
                           Use n_jobs=-1 for parallelism

Memory error                Reduce CV folds (3 instead 5)
                           or reduce data size

Features not improving      Maybe giÃ  buono V25,
                           or need more/different features
```

---

## ðŸŽ¯ SUCCESS CRITERIA

âœ… **V26 Ã¨ successful se:**

1. **No errors**: Script runs without exceptions
2. **Better accuracy**: V26 > V25 (e.g., 55% > 50%)
3. **Reasonable timing**: Training < 20 seconds
4. **Stable results**: Accuracy consistent across runs
5. **Production ready**: Can process real matches

âŒ **Rollback a V25 se:**

1. Accuracy peggiore di V25
2. Training time > 5 minuti
3. Memory issues
4. Frequent NaN/errors
5. Probabilities non affidabili

---

## ðŸ“ž QUICK HELP

**Q: Quale opzione scelgo?**
A: Se nuovo alla ML â†’ QUICK (A). Se esperto â†’ EXPERT (C).

**Q: Quanto migliora davvero?**
A: 5-7% realistico. 9-12% se tutto perfetto.

**Q: Torno a V25 dopo V26?**
A: SÃ¬, se accuracy peggiore o troppo lento.

**Q: Gridserach fa differenza?**
A: +1-2% ma aggiunge 5-10 min training.

**Q: Serve CalibratedClassifierCV?**
A: SÃ¬, per probabilitÃ  affidabili nelle scommesse.

---

**Pronto? Inizia con la lettura di IMPLEMENTATION_GUIDE_V26.md! ðŸš€**
